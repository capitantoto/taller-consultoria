---
title: "Taller de Consultoria - TP1"
author: "Gonzalo Barrera Borla"
date: "8/25/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Setup
```{r, echo=TRUE, message=F}
library(fitdistrplus) # ajuste exploratorio de distribuciones
library(tidyverse) # manipulación de datos en general
library(broom) # limpieza y estructuracion de resultados de regresiones
library(RobStatTM) # regresiones robustas
```

# Problema 1

Se dan las duraciones (medidas en ciclos hasta la ruptura) de una muestra de rodamientos (“rulemanes”). Describir las características principales de la muestra (posición, dispersión, asimetría), y buscar una  distribución adecuada.

Los funcionales de locación más habituales son la media $\mu$ y la mediana $\eta$, digamos. Reportamos sus estimadores puntuales muestrales, $\hat{\mu}=\bar{x}=n^{-1}\sum_i x_i$ y $\hat{\eta}=x^{(\frac{n}{2})}$ (donde $x^{(i)}$ denota el i-ésimo elemento de la muestra ordenada). 	Para la dispersión, es razonable usar el la raíz cuadrada del estimador puntual insesgado de la varianza, $s^2=(n-1)^{-1}\sum_i(x_i-\bar{x})^2$. Para la asimetría $\gamma$, construimos el estimador $b$ reemplazando en la definición de $\gamma$ a cada momento por su estimador insesgado:

$$
\begin{split}
\gamma&=E\left[\left(\frac{X-\mu}{\sigma}\right)^3\right] \\
b=\hat{\gamma}&=\frac{1}{n}\sum_{i=1}^{n}\left(\frac{x_i-\bar{x}}{s}\right)^3
\end{split}
$$

```{r}
asimetria <- function(x) {
  s <- sd(x)
  x_ <- mean(x) # "x raya"
  b <- ((x - x_) / s)^3
  return(mean(b))
}
```

```{r, message=F}
df1 <- read_csv("data/1-1.csv")
df1 %>%
  summarise(
    media = mean(duracion),
    mediana = median(duracion),
    `dispersión` = sd(duracion),
    `asimetría` = asimetria(duracion)
    ) %>%
  knitr::kable(digits = 3)
```

Comparamos nuestra funcion de asimetría con la implementación de un paquete bien conocido de R para comprobar su coherencia:

```{r, echo=TRUE}
casi_iguales <- function(x, y, tol=1e-6) { abs(x-y) <= tol }  
stopifnot(casi_iguales(
  e1071::skewness(df1$duracion),
  asimetria(df1$duracion)))
```

La distribución más habitual para modelar la vida media de individuos/componentes es la Weibull, que generaliza la bien conocida distribución exponencial para considerar tasas de fallo no necesariamente constantes en el tiempo. Se dice que $X \sim \text{Weibull}(k, \lambda)$ con parámetros de _forma_ $k>0$ y _escala_ $lambda>0$ si la densidad de $X$ está dada por:

$$
f(x;\lambda,k) =
\begin{cases}
\frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}} & x\geq0 ,\\
0 & x<0,
\end{cases}
$$

Nótese que cuando $k=1$, la tasa de fallos es constante, y $X\sim\text{Exp}(\lambda^{-1})$.

El estimador de máxima verosimilitud de $\lambda$ dado $k$ ([referencia](https://en.wikipedia.org/wiki/Weibull_distribution)) es

$$
\widehat \lambda^k = \frac{1}{n} \sum_{i=1}^n x_i^k
$$

Mientras el el EMV de $k$ es la solución para $k$ de la siguiente ecuación, que ha de ser encontrado numéricamente:
$$
0 = \frac{\sum_{i=1}^n x_i^k \ln x_i }{\sum_{i=1}^n x_i^k }
    - \frac{1}{k} - \frac{1}{n} \sum_{i=1}^n \ln x_i
$$

A continuación, implementamos la búsqueda antes descrita y la comparamos con el resultado de una implementación estándar, `fitdistrplus::fitdist`.

```{r, echo=TRUE}
ajustar_weibull <- function(x, rango_forma = c(0, 10)) {
  eq_k <- function(x, k){ sum((x^k) * log(x)) / sum(x^k) -1/k -mean(log(x)) }
  # Busco numéricamente el k que minimiza la distancia a 0 de eq_k
  k <- optimise(function(k){abs(eq_k(x, k))}, interval = rango_forma)$minimum
  lambda <- mean(x^k)^(k^-1)
  return(c(forma = k, escala = lambda))
}
```

```{r}
fd_wei <- fitdistrplus::fitdist(df1$duracion, distr = "weibull", method = "mle")
yo_wei <- ajustar_weibull(df1$duracion)
stopifnot(
  casi_iguales(yo_wei["forma"], fd_wei$estimate["shape"], tol = 2e-4),
  casi_iguales(yo_wei["escala"], fd_wei$estimate["scale"], tol = 2e-3))
```

La implementación propia es casi idéntica a la estándar con una diferencia del `r ((yo_wei["forma"] - fd_wei$estimate["shape"])/fd_wei$estimate["shape"] * 100) %>% round(4)`% para el parámetro de forma y `r ((yo_wei["escala"] - fd_wei$estimate["scale"])/fd_wei$estimate["scale"] * 100) %>% round(4)` para el de escala. ¡Nada mal! A continuación, aprovechamos los gráficos por defecto del objeto `fitdist`, en particular el plot cuantial-cuantil ("Q-Q") para convencernos de que el ajuste es decente:

```{r}
plot(fd_wei)
```

En conclusión, postulamos que las duraciones $X_i$ de los $i=1,\dots,n$ rodamientos están distribuidas con $X_i \stackrel{iid}{\sim} \text{Weibull}(k=`r yo_wei["forma"] %>% round(3)`, \lambda = `r yo_wei["escala"] %>% round(3)`)$.


# Problema 2

Se dan: el punto de ebullición del agua (PE) (en grados Fahrenheit) y la presión atmosférica (PA) (en pulgadas de mercurio), medidos a distintas alturas en los Alpes. Plantear un modelo que describa cómo varía PE en función de PA. ¿Con cuánta precisión se puede estimar PE en función de PA?. Comentar cualquier característica de los datos.

Convertimos primero las unidades al sistema métrico, y las graficamos.

```{r}
df2 <- read_csv("data/1-2.csv")
inHg_a_atm <- function(x) {x/29.921}
fahrenheit_a_celsius <- function(x) { (x - 32)*5/9 }

df2 <- df2 %>%
  mutate(
    id = seq_along(PA),
    PE = map_dbl(PE, fahrenheit_a_celsius),
    PA = map_dbl(PA, inHg_a_atm)) 

df2 %>%
  ggplot(aes(PA, PE)) +
  geom_point()
```

Se observa una relación casi lineal ($PE=b + m\times PA$), salvo por una tozuda observación cerca de (0.9, 95.0). Intentemos una sencilla regresión lineal en la PA, y grafiquemos los residuos en función de la misma.
```{r}
lm2 <- lm(PE ~ PA, df2)
b <- round(lm2$coefficients[1], 2)
m <- round(lm2$coefficients[2], 2)

summary(lm2)
```
Tanto la ordenada al origen como la pendiente parecen ser sin duda significativas, y nuestro modelo ajustado queda:

$$
PE = `r b`^\circ C + `r m` \frac{^\circ C}{atm} \times PA 
$$
Vale aclarar que este modelo sólo tiene sentido sobre el soporte de los datos, es decir, cuando la presión atmosférica está en el rango $(`r range(df2$PA) %>% round(2)`)$. Si no, podríamos deducir incorrectamente que la temperatura de ebullición del agua en el vacío (0 atm.) es de `r b` grados, cuando en realidad es de ~-68 grados celsius ([referencia](https://www.engineeringtoolbox.com/water-evacuation-pressure-temperature-d_1686.html)).

Observamos los "residuos" ($r_i = y_i - \hat{y}_i$) versus la presión atmosférica para ver con cuánta precisión se puede estimar el punto de ebullición, y examinarlos por si existe alguna estructura.
```{r}
df2 <- augment(lm2, data = df2)

df2 %>%
  ggplot(aes(PA, PE)) +
  geom_point() +
  geom_abline(intercept = b, slope = m, color = 'red')

df2 %>%
  ggplot(aes(PA, .resid, label=id)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = 'gray') +
  geom_text(
    data = filter(df2, abs(.resid) > 0.5),
    nudge_x = 0.01)
```

Vemos que en general, la predicción del punto de ebullición está errada por menos de $0.25^\circ C$, a excepción de la observación 12, donde el error es de `r filter(df2, id==12) %>% pull(".resid") %>% round(2)` grados.

Se me ocurren dos caminos para mejorar este modelo. Uno, es realizar un ajuste robusto. Lo intentamos (con `RobStatTM::lmrobdetMM`), pero la situación no mejora demasiado. Una estrategia más sabia, sería plantear un modelo matemático con una descripción realista del fenómeno. Leyendo por la [internet](http://physicstasks.eu/1702/boiling-point-of-water-at-high-pressure) veo que la relación entre PA y PE es más bien exponencial, así que podríamos plantear un modelo tansformado acorde. Sin embargo, para el rango de PA considerado, pareciera má que razonable que la relación es lineal, y la santa observación #12 es más bien una mala medición de laboratorio.

```{r}
cont <- lmrobdet.control(
  bb = 0.5, efficiency = 0.85, family = "bisquare")
lm2rob <- lmrobdetMM(PE ~ PA, data=df2, control=cont)
df2 %>%
  mutate(rob_resid = lm2rob$residuals) %>%
  ggplot(aes(PA, rob_resid)) +
  geom_point()
```

# Problema 3

Se investiga el efecto de la presión aplicada durante la manufactura del papel, en el “factor de ruptura” (la fuerza necesaria para desgarrarlo). Bajo cada valor de la presión P, se manufacturó  un lote de papel; de cada lote se eligieron 4 hojas, a cada una de las cuales se midió el factor de ruptura R. Se desea predecir R en función de P.

```{r}
df3 <- read_csv("data/1-3.csv")
```

Aprovechando que tenemos mediciones repetidas para cada uno de los 5 valores de P, comparamos la raíz cuadrada del estimador global de la varianza $s_0 = `r round(sd(df3$R), 2)`$, con la de los estimadores de la varianza para cada valor de P:
```{r}
df3 %>%
  group_by(P) %>%
  summarise(s = sd(R)) %>%
  knitr::kable(digits = 2)
```

Aún con pocos datos, se intuye que la varianza en R no es la misma para todo P. Pareciera haber _heterocedasticidad_, pero la relación entre P y la varianza de R no es lineal: $s$ es máximo para presiones "medias" de fabricación.

Asumiendo que las mediciones de cada par $(P, R)$ son independientes entre sí, la matriz de covarianzas será diagonal, y en vez de utilizar $\Sigma = \sigma^2 \mathrm{I}_n$, podemos considerar una matriz $\Sigma = diag(\sigma_1^2, ..., \sigma_n^2)$, y estimar las varianzas de cada observación, con el estimador insesgado de la varianza para cada nivel de presión antes calculado.

A continuación ajustamos ambos modelos, considerando (a) observaciones iid en general, y matriz de covarianza $\sigma^2 \mathrm{I}_n$, y (b) observaciones iid _en cada nivel de P_, con $\Sigma = diag(\sigma_1^2, ..., \sigma_n^2)$. Este último modelo equivale a realizar un ajuste de mínimos cuadrados pesados, con pesos $w_i = \sigma_i^{-2}$

```{r}
df3 <-  df3 %>%
  group_by(P) %>%
  mutate(s = sd(R))

lm3a <- lm(R ~ P, df3)
lm3b <- lm(R ~ P, df3, weights = s^-2)

b <- lm3b$coefficients[1] %>% round(2)
m <- lm3b$coefficients[2] %>% round(2)

map_df(
  list(ordinario = lm3a, pesado = lm3b),
  glance, .id = 'modelo') %>%
  select(modelo, adj.r.squared, p.value) %>%
  knitr::kable()
```

Aunque ambos modelos son buenos, el p-valor para la regresión global del segundo modelo es más de 3 órdenes de magnitud más pequeño. La evidencia parece justificar el uso de una regresión pesada. El modelo final quedará

$$
R = `r b` + `r m` atm^{-1} \times P 
$$

NOTA: Graficar ambas rectas sobre los datos, ver que la diferencia es mínima.

# Problema 4

La siguiente tabla da, para 12 huevos de gallina, la longitud L (o sea, el mayor diámetro), la mayor sección circular (el mayor diámetro perpendicular a L), ambas en pulgadas;  y el volumen V. Interesa predecir V en función de L y M. 

Preston (1973) ([link](https://sora.unm.edu/sites/default/files/journals/auk/v091n01/p0132-p0138.pdf)) hace un tratamiento bastante exhaustivo de cómo calcular el volumen de un huevo, que a continuación resumimos.

Supongamos que el mayor diámetro de un huevo es $M$, y su largo es $L=a+b$, donde $a,\:b$ son las dos partes en que se divide el largo a la altura del máximo diámetro. El volumen de todo huevo está acotado superiormente por un ciindro perfecto de diámetro $M$, y por debajo por un bicono de máximo diámetro $M$ y alturas $a,\:b$. Si el huevo fuese cilíndrico, su volumen será $\tfrac{\pi}{4}M^2L$, y si fuese bicónico, $\tfrac{\pi}{12}M^2L$. En un escenario más realista e intermedio, en que el huevo está formado por dos medios elipsoides, su volumen es $\tfrac{\pi}{6}M^2L$. Nótese que en ningún caso la asimetría (_id est_, cuán lejos de $L/2$ están $a$ y $b$) hace diferencia alguna, pero sí es clave saber la forma dominante (bicono, elipsoide, cilindro). Los huevos de [colibrí](http://www.fotonatura.org/galerias/fotos/295043/) son más bien romos, casi cilíndricos, mientras que los de [zampullín](https://en.wikipedia.org/wiki/Great_crested_grebe#/media/File:Podiceps_cristatus_MWNH_0106.JPG) son casi bicónicos. En el siguiente gráfico, exhibimos los posibles volúmenes de cada huevo según la suposición de forma:

```{r}
df4 <- read_csv("data/1-4.csv")
volumenes <- df4 %>%
  arrange(V) %>%
  mutate(
    real = V,
    id = seq_along(V),
    bicono = pi/12 * M^2 * L,
    elipsoide = pi/6 * M^2 * L,
    cilindro = pi/4 * M^2 * L) %>%
  select(id, real, bicono, elipsoide, cilindro) %>%
  gather(forma, volumen, -id)

volumenes %>%
  ggplot(aes(id, volumen, color = forma)) +
  geom_point()
```

El formato más razonable parece ser un cilindro, así que si el volumen del huevo de gallina está dado por ĺa fórmula $V=kM^2L$, $k\approx\pi/4$. Sin embargo, una simple regresión lineal sobre $M$ y $L$ que incluya un término cuadrático sobre $M$ ya tiene un error cuadrático medio mucho menor que nuestro modelo de huevo cilíndrico:
```{r}
lm4a <- lm(V ~ poly(M, 2) + L, df4)
df4a <- augment(lm4a, data = df4)
df4a %>%
  mutate(cilindro = pi/4 * M^2 * L) %>%
  summarise(
    "ecm_lm" = mean(.resid^2),
    ecm_cil = mean((V - cilindro)^2)) %>%
  knitr::kable(digits = 4)
```

Una forma directa de mejorar el modelo, es usar una regresión lineal _sin ordenada_, sobre una covariable "sintética", $V = k \times (M^2\cdot L)$ y estimar empíricamente $k$.
```{r}
df4 <- df4 %>%
  mutate(M2L = M^2*L)
lm4b <- lm(V ~ M2L + 0, df4)
k <- lm4b$coefficients[1] %>% round(3)
ecm <- function(lm_call) { mean(lm_call$residuals^2) }
map_df(
  list(polinomico = lm4a, fisico = lm4b),
  glance, .id = 'modelo') %>%
  select(modelo, adj.r.squared, p.value) %>%
  knitr::kable(digits = 4)
```

¡Y cómo mejora! Evidentemente, con un $R^2_{adj}$ tan cercano a 1, algo debemos haber hecho bien. Es interesante notar que si comparásemos los dos modelos según su error cuadrático medio, ,el "polinómico" ingenuo da `r ecm(lm4a) %>% round(4)` y el "físico" basado en una teoría real sobre la forma de los huevos de aves, da `r ecm(lm4b) %>% round(4)`. Las predicciones del modelo polinómico tienen menor error cuadrático medio, pero el modelo físico es tanto más parsimonioso (ajusta 1 sólo parámetro en lugar de 4), que termina siendo ampliamente preferible. Así, concluimos que el mejor modelo para predecir $V$ es $V = `r k`\times M^2 \times L$.



