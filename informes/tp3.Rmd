---
title: "Taller de Consultoria - TP3"
author: "Gonzalo Barrera Borla"
date: "12/09/2019"
output:
  pdf_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(tinytex.verbose = TRUE)
```

# Setup
```{r, echo = T}
library(tidyverse) # manipulación de datos en general, graficos
library(broom) # limpieza y estructuracion de resultados de regresiones
library(GGally) # gráficos de perfiles, entre otros
library(gridExtra) # Paginado de gráficos 
```

# Ejercicio 1

```{r}
tipo_cols <- cols(
  maceta = col_integer(),
  cruz = col_double(),
  auto = col_double()
)
df1 <- read_csv("../data/3-1.csv", col_types = tipo_cols)
```

>  Los datos siguientes corresponden a un experimento realizado por Charles Darwin en 1876. En cada maceta se plantan dos brotes de maíz, uno producido por fertilización cruzada, y el otro por auto-fertilización. El objetivo era mostrar las ventajas de la fertilización  cruzada. Los datos son las altura finales de las plantas después de un período de tiempo. ¿Alguno de los dos tipos de maíz es demostrablemente mejor?. Si es así, ¿cómo se puede describir la diferencia?. 

Sea $\Omega_0$ la familia de distribuciones tal que

$$
\Omega_0 = \{F:F \text{ es absolutamente continua con única mediana en }0\}
$$
Sea $Y_i$ la altura del brote de maíz producido por fertilización cruzada de la  maceta $i\in\{1,\dots,n\}, n=15$, y $X_i$ la altura del producido por auto-fertilización. Supondremos además, razonablemente, que  $Y_i \stackrel{iid}{\sim} F_Y(t)=F(t-\theta_Y), \: F \in \Omega_0$ (es decir que $F_Y$ es absolutamente continua con única mediana en $\theta_Y$). Análogamente, $X_i \stackrel{iid}{\sim} F_X(t)=F(t-\theta_X)$. Como _"el objetivo era mostrar las ventajas de la fertilización  cruzada"_, una forma razonable de plantear este test será:

$$
H_0 := \theta_Y = \theta_X \quad \text{vs.} \quad H_1:= \theta_Y > \theta_X
$$
Como los brotes están naturalmente apareados en sus respectivas macetas, es razonable realizar un test de muestras apareadas. Para determinar qué clase de test realizar, nos resta contestar: ¿Es normal la distribución de las alturas de ambos tipos de brotes? Si la respuesta es "sí", podemos usar un "test t", mientras que si no será conveniente recurrir a alguna  alternativa no paramétrica, como el test de Wilcoxon de rangos signados, que sólo requiere que la distribución bajo la hipótesis nula sea simétrica.

Para examinar la normalidad de los datos, comenzamos por graficar un QQ-plot y la estimación empírica de la densidad de cada tipo de maíz, y de la diferencia de alturas por maceta:

```{r}
df1 <- df1 %>%
  mutate(diferencia = cruz - auto)

df1 %>%
  gather("tipo", "valor", -maceta) %>%
  ggplot(aes(sample = valor, color = tipo)) +
  geom_qq() +
  geom_qq_line() +
  facet_wrap(~ tipo, scale = "free_y") +
  theme(legend.position = "bottom") +
  labs(title = "QQ-plot normal")

df1 %>%
  gather("tipo", "valor", -maceta) %>%
  ggplot(aes(valor, color = tipo)) +
  geom_density() +
  facet_wrap(~ tipo, scale = "free_x") +
  theme(legend.position = "bottom") +
  labs(title = "Densidades empíricas")
```


Las densidades individuales _podrían_ llegar a ser normales, aunque tienen colas a izquierda un tanto pesadas, lo cual se nota aún más en la densidad de las diferencias. Sin embargo, los QQ-plots revelan observaciones decididamente atípicas. Aquí, podríamos decidir descartar las observaciones atípicas y repetir los gráficos previos, pero preferimos simplemente abandonar el supuesto de normalidad, y recurrir a un test no paramétrico.

Nótese que bajo $H_0 := \theta_Y = \theta_X \Rightarrow \: F_X=F_Y$, de manera que la distribución de $Y_i - X_i$ será simétrica, y podemos utilizar un test de Wilcoxon para datos apareados con confianza.

```{r}
alfa <- 0.05
wcx_apar <- wilcox.test(df1$cruz, df1$auto, paired = T, alternative = "g",
                        conf.int = T, conf.level =1-alfa)
wcx_2samp <- wilcox.test(df1$cruz, df1$auto, paired = F, alternative = "g",
                        conf.int = T, conf.level = 1-alfa)
t_apar <- t.test(df1$cruz, df1$auto, paired = T, alternative = "g",
                        conf.int = T, conf.level = 1-alfa)
t_2samp <- t.test(df1$cruz, df1$auto, paired = F, alternative = "g",
                        conf.int = T, conf.level = 1-alfa)
```

Este test arroja un p-valor de `r signif(wcx_apar$p.value, 2)`, de manera que con el tradicional criterio de significación $\alpha = `r alfa`$, podemos rechazar la hipótesis nula y concluir que la diferencia entre las medianas de los brotes de fertilización cruzada y los autofertilizados es positiva. Aprovechando el hecho de que el estadístico $T^+$ del test de Wilcoxon es un estimador de Hodges-Lehmann, podemos encontrar también el intervalo de confianza de nivel `r 100*(1-alfa)`% correspondiente al test, que resulta ser $[`r wcx_apar$conf.int`)$.

Por último, y a modo ilustrativo, incluimos en la siguiente tabla los p-valores y límites inferiores de los intervalos de confianza de nivel `r 100*(1-alfa)`% correspondientes a cuatro alternativas de test razonables en este problema. Al ser todas alternativas de un mismo test a una cola, el límite superior del IC es siempre
$+\infty$.

```{r}
tribble(
  ~Muestras, ~Test, ~llamada,
  "apareadas", "Wilcoxon", wcx_apar,
  "2 muestras", "Wilcoxon", wcx_2samp,
  "apareadas", "T de Student", t_apar,
  "2 muestras", "T de Student", t_2samp) %>%
  mutate(
    "p-valor" = map_dbl(llamada, "p.value"),
    "Lím. inf. IC" = map(llamada, "conf.int") %>% map_dbl(1)
  ) %>%
  select(-llamada) %>%
  knitr::kable(digits = 4)
```

Es decir, que en todos los casos hubiésemos rechazado la hipótesis nula a nivel 5%, pero la estimación de la diferencia en las medianas/medias hubiese sido bastante distinta.

# Ejercicio 2

> Se dan a continuación los tiempos de sobrevida (en unidades de 10 horas) de animales, sometidos a 3 tipos de veneno, y 4 tratamientos antitóxicos. Cada combinación veneno-tratamiento se prueba con 4 animales.  Describir la influencia de ambos factores en la sobrevida.  ¿Hay algún tratamiento demostrablemente mejor?

Para hacer más intuitiva la información, cambiamos las unidades de `sobrevida` de modo que esté en horas. Sea  $y_{ijk}$ la sobrevida del $k$-ésimo animal, sometida al tratamiento $j$ para el veneno $i$, en general planteamos $y_{ijk} = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon_{ijk}$, donde $i \in \{I, II, III\}, \: j \in \{A, B, C, D\}, \: k \in \{1, 2, 3, 4\}$ y $\epsilon_{ijk} \sim N(0, \sigma^2)$.

Para darnos una idea de la relación entre venenos y tratamientos, comenzamos graficando los perfiles:

```{r}
tipo_cols <- cols()
raw2 <- read_csv("../data/3-2.csv", col_types = tipo_cols)
df2 <- raw2 %>%
  gather("trt", "sobrevida", -veneno) %>%
  mutate(
    trt = as_factor(trt),
    sobrevida = sobrevida * 10)

g3 <- df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(mean)%>%
  spread(veneno, sobrevida) %>%
  ggparcoord(2:4, "trt") +
  labs(title = "Dif. con la media por tratamiento",
       x = "Veneno", y = "Sobrevida (hs)", color = "Trat.") +
  theme(legend.position = "bottom")

g4 <- df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(mean)%>%
  spread(trt, sobrevida) %>%
  ggparcoord(2:5, "veneno") +
  labs(title = "Dif. con la media por veneno",
       x = "Tratamiento", y = "Sobrevida (hs)", color = "Veneno") +
  theme(legend.position = "bottom")

grid.arrange(g3, g4, ncol = 2)
```

A primera vista, no se observa paralelismo en ninguno de los dos gráficos Sin embargo, salvo un ligero entrecruzamiento en los perfiles de los venenos II y III para los tratamientos C y D, los perfiles no se cruzan en ningún otro punto, por lo que tal vez sea razonable ignorar las interacciones y considerar un modelo de efectos únicamente aditivos.

Por otra parte, debemos corroborar el fortísimo supuesto de _homocedasticidad_ de los $\epsilon_{ijk}$ que hicimos inicialmente. Seber [1977, p. 195] siguiendo a Scheffé menciona como heurística que cuando se cuenta con un diseño balanceado como aquí, la desigualdad en las varianzas para cada combinación de bloque y tratamiento no hace demasiado "daño", siempre y cuando la razón entre el mayor y el menor desvío estándar sea menor a 2. Lamentablemente, nuestros datos son "bochornosos" en tal sentido:

```{r}
df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(lst(mean, sd)) %>%
  arrange(desc(sd)) %>%
  knitr::kable(
    digits = 3,
    caption = "La tasa entre los desvios de II:B y III:C es mayor a 26")
```

Antes de proseguir, nos convendrá entonces considerar una transformación [estabilizadora de la varianza](https://en.wikipedia.org/wiki/Variance-stabilizing_transformation) que al menos morigere esta situación. 

Si graficamos el desvío en función de la media de cada grupo, observamos una estructura razonablemente lineal en la media:

```{r}
df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(lst(mean, sd)) %>%
  ggplot(aes(mean, sd, color = trt, shape = veneno)) +
  geom_point() +
  labs(title = "Relación entre desvío y media muestral por población",
       subtitle = "Datos originales de sobrevida",
       x = "Media", y = "Desvío", shape = "Veneno", color = "Trat.")
```

En este caso, donde $\sigma \approx k \times \mu$, la transformación sugerida es el logaritmo. Esto es razonable, ya que al hablar por ejemplo del logaritmo base 2 de la _sobrevida_, un tratamiento que duplica la supervivencia, aumentará $\log_2(y)$ en una unidad. Aplicando esta transformación, la razón entre el máximo y mínimo desvíos anteriormente mencionada mejora bastante, pero sigue estando por encima de 7, muy lejos del corte de 2 que propone Seber.

Haremos un intento más, y en lugar de considerar la transformación logarítmica, buscaremos la transformación "óptima" según este criterio de optimalidad, de entre la familia de transformaciones [Box-Cox](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation) de un parámetro, que incluye el logaritmo natural como un caso especial cuando $\lambda=0$:

$$
y_i^{(\lambda)} =
\begin{cases}
 \dfrac{y_i^\lambda - 1}{\lambda} & \text{if } \lambda \neq 0, \\
 \ln y_i & \text{if } \lambda = 0,
\end{cases}
$$

Si graficamos la relación entre el mayor y menor desvío estándar por bloque y tratamiento para distintos $\lambda$, observamos que el mínimo se encuentra alrededor de $\lambda=-0.87$, que lleva la tasa de desvíos a $\approx 3.6$:

```{r}
boxcox <- function(y, lambda) {
  if (lambda == 0) {log(y)} else {(y^lambda - 1)/lambda}
}
evaluar_lambdas <- function(lambdas) {
  tasas <- vector("numeric", length(lambdas))
  for (i in seq_along(lambdas)) {
    l <- lambdas[i]
    desvios <- df2 %>%
      mutate(y = boxcox(sobrevida, lambda = l)) %>%
      group_by(veneno, trt) %>%
      dplyr::summarise(desvio = sd(y)) %>%
      pull("desvio")
    tasas[i] <- max(desvios)/min(desvios)
  }
  return(tibble(l = lambdas, t = tasas))
}

lambdas <- evaluar_lambdas(seq(-1.5, 0, 0.01))
  
lambdas %>%
  ggplot(aes(l, t)) +
  geom_line() +
  geom_hline(yintercept = min(lambdas$t), linetype = "dotted") +
  geom_vline(xintercept = lambdas$l[which.min(lambdas$t)], linetype = "dotted") +
  labs(title = expression(paste("Razón del máximo al mínimo desvío por población para distintos ", lambda)),
       x = expression(lambda), y=expression(paste("max ", sigma, " / min ", sigma)))
```

Reducir la tasa de desvíos a 3.6 sigue sin ser suficiente para el criterio originalmente autoimpuesto, pero tampoco está demasiado lejos, y es una enorme mejoría respecto a la tasa original de más de 26, así que aplicaremos la transformación de Box-Cox y calificaremos momentáneamente de "tolerable" la heterocedasticidad restante. Lo que sí, para ayudar a la comprensión, en lugar de tomar el óptimo $\lambda^{\star}=-0.87$, tomaremos el mucho más interpretable $\lambda=-1$, que consigue una tasa de desvíos similar (4.12), pero provee una transformación más clara: $g(y) = 1 - \tfrac{1}{y}$, tal que cuando $y \in (1, + \infty) \Rightarrow g(y) \in (0, 1)$.

Aplicamos la transformación, y volvemos a graficar los perfiles.

```{r}
df2$y_ <- boxcox(df2$sobrevida, -1)

df2 %>%
  group_by(veneno, trt) %>%
  summarise_at(vars(y_), lst(mean, sd)) %>%
  ggplot(aes(mean, sd, color = trt, shape = veneno)) +
  geom_point() +
  labs(title = "Relación entre desvío y media muestral por población",
     subtitle = "Datos transformados con g(y) = 1 - 1/y",
     x = "Media", y = "Desvío", shape = "Veneno", color = "Trat.")

g5 <- df2 %>%
  group_by(veneno, trt) %>%
  summarise_at(vars(y_), mean)%>%
  spread(veneno, y_) %>%
  ggparcoord(2:4, "trt") +
  labs(title = "Dif. con la media por tratamiento",
       x = "Veneno", y = "Sobrevida (hs)", color = "Trat.") +
  theme(legend.position = "bottom")


g6 <- df2 %>%
  group_by(veneno, trt) %>%
  summarise_at(vars(y_), mean)%>%
  spread(trt, y_) %>%
  ggparcoord(2:5, "veneno") +
  labs(title = "Dif. con la media por veneno",
       x = "Tratamiento", y = "Sobrevida (hs)", color = "Veneno") +
  theme(legend.position = "bottom")


grid.arrange(g5, g6, ncol = 2)

```

Las varianzas observadas para cada tratamiento y veneno ahora ya no presentan ninguna tendencia obvia, y aunque no sean realmente paralelos los perfiles, al menos no se observan entrecuzamientos. Comenzamos planteando un modelo con interacciones, $y_{ijk} = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon_{ijk}$, y comenzamos testeando la hipótesis de "no-interacción" $H_0: \gamma_{ij} = 0 \:\forall \: i \in \{II, III\}, j \in \{B, C, D\}$:

```{r}
mult <- lm(y_ ~ veneno * trt, df2)
tidy(anova(mult)) %>%
  transmute(
    "Coefs" = term,
    "GL" = df,
    "C. Medios" = as.character(signif(statistic, 3)),
    "F obs." = as.character(signif(statistic, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()
```

Efectivamente, no sólo el p-valor del estadístico F correspondiente a las interacciones es altísimo, sino que la razón entre los "cuadrados medios" de las interacciones y cualquiera de los tratamiento es realmente muy pequeña, así que podemos despreocuparnos de las interacciones. A continuación consideramos un modelo aditivo únicamente, y repetimos los tests de significativadad para los efectos principales, tanto de los tratamientos como de los venenos. Mantenemos la transformación de la variable respuesta con $\lambda = -1$, ya que la elección del parámetro se realizó independientemente del modelo a ajustar.

$$
y_{ijk} = \mu + \alpha_i + \beta_j + \epsilon_{ijk} \quad \text{con }\: \epsilon_{ijk} \sim N(0, \sigma^2)
$$

Los principales descriptores del modelo muestran que

- es globalmente significativo,
- tanto los efectos principales de los venenos como de los tratamientos son significativos y
- todos los coeficientes son significativamente distintos de 0 a nivel 0.01 o menor:

```{r}
adit <- lm(y_ ~ veneno + trt, df2)

glance(adit) %>%
  transmute(
    "R^2 aj." = as.character(signif(adj.r.squared, 3)),
    "F obs." = as.character(signif(statistic, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()

tidy(anova(adit)) %>%
  transmute(
    "Coefs" = term,
    "GL" = df,
    "C. Medios" = as.character(signif(statistic, 3)),
    "F obs." = as.character(signif(statistic, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()

tidy(adit) %>%
  transmute(
    "Coef." = term,
    "Estimado" = as.character(signif(estimate, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()
```

Graficamos el módulo de los residuos estudentizados contra los valores ajustados $\widehat{g(y)}$, y nos tranquiliza la ausencia de estructura evidente. Hay una observación con un residuo $>2.5$ que puede merecer mayor consideración, pero resulta razonable dejarla así, ya que de quitarla el diseño deja de ser balanceado, y ya bastantes transformaciones hemos tenido que hacer para obtener el modelo actual. Tampoco encontramos desviaciones egregias de la normalidad en el QQ-plot, así que consideramos aceptable al modelo.

```{r}
augment(adit) %>%
  ggplot(aes(.fitted, abs(.std.resid), color = trt, shape = veneno)) +
  geom_point() +
  labs(title = "Residuos estudentizados en función del valor predicho",
       x = expression(paste(hat(g),"(y)")), y = "Residuo estud.",
       color = "Trat.", shape = "Veneno")

augment(adit) %>%
  ggplot(aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "QQ-plot de los residuos del modelo aditivo",
     x = "Cuantil Teórico", y = "Residuo")
```

Nos resta _describir_ la influencia de los venenos y los tratamientos en la sobrevida, con la complicación de que estamos trabajando sobre datos transformados. Como la trasformación es estrictamente creciente en la sobrevida, el signo de los efectos se mantiene. En principio en orden _creciente_ de sobrevida,

- los venenos se ordenan $III<II<I$, y
- los tratamientos se ordenan $A<C<D<B$.

Usando el método de "Diferencias Significativas Honestas" de Tukey, podemos comparar de a pares los venenos y tratamientos. En las unidades transformadas $g(y)$ que venimos trabajando, todos los venenos y tratamientos son distintos entre sí, salvo los tratamientos D y B, para los cuales el IC de su diferencia de medias incluye al 0.

```{r}
#TukeyHSD(aov(sobrevida ~ veneno + trt, df2))
tidy(TukeyHSD(aov(y_ ~ veneno + trt, df2))) %>%
  transmute(
    "Coef." = term,
    "Comp." = comparison,
    "Dif. medias" = as.character(signif(estimate, 3)),
    "Lím. inf. IC" = as.character(signif(conf.low, 3)),
    "Lím. sup. IC" = as.character(signif(conf.high, 3)),
    "P-valor" = as.character(signif(adj.p.value, 3)),
) %>%
  knitr::kable()
```

La inferencia mas allá de estas conclusiones es algo limitada. En primer lugar, al no contar con un control, ni siquiera podemos argumentar que alguno de los tratamientos sea más efectivo que un simple placebo. Por otra parte, tampoco tenemos una forma directa de responder _por cuánto_ mejora la sobrevida en términos absolutos en la escala original. Lo que sí podemos ofrecer, es $g^{-1}(\hat{\mu}+\hat{\alpha}_i+\hat{\beta}_j)$ como una aproximación de la sobrevida media para cada combinación de venenos y tratamientos. Ordenadas por $g^{-1}$, tenemos:

```{r}
ginv <- function(y) {1/(1-y)}

resumen2 <- augment(adit) %>%
  select(veneno, trt, y_, .fitted) %>%
  transmute(
    veneno, trt,
    original = ginv(y_),
    ajustada = ginv(.fitted)) %>%
  group_by(veneno, trt) %>%
  summarise_all(mean) %>%
  ungroup()

resumen2 %>%
  arrange(desc(ajustada)) %>%
  transmute(
    veneno, trt,
    orig = as.character(signif(original, 3)),
    ajust = as.character(signif(ajustada, 3))
  ) %>%
  knitr::kable(col.names = c("Veneno", "Tratamiento", "Original", "Ajustada"))
```

O si lo preferimos, podemos volver a graficar los perfiles de sobrevida por veneno y tratamiento, con los valores originales y los ajustados. Esta vez, no restamos la media, para darnos una mejor idea de las sobrevidas comparadas:

```{r}
resumen2 %>%
  gather("Tipo", "Sobrevida", -veneno, -trt) %>%
  group_by(veneno, trt, Tipo) %>%
  summarise_all(mean) %>%
  ggplot(aes(veneno, Sobrevida, linetype = Tipo, color = trt, group = paste(trt, Tipo))) +
  geom_line() +
  labs(title = "Perfiles de sobrevida (original y ajustada) para cada tratamiento",
       x = "Veneno", color = "Tratamiento")

resumen2 %>%
  gather("Tipo", "Sobrevida", -veneno, -trt) %>%
  group_by(veneno, trt, Tipo) %>%
  summarise_all(mean) %>%
  ggplot(aes(trt, Sobrevida, linetype = Tipo, color = veneno, group = paste(veneno, Tipo))) +
  geom_line() +
  labs(title = "Perfiles de sobrevida (original y ajustada) para cada veneno",
       x = "Tratamiento", color = "Veneno")
```


# Ejercicio 3

> Un ensayo de aberración cromosómica sirve para determinar si una sustancia produce cambios estructurales en los cromosomas.  Los datos que siguen muestran los resultados de la aplicación de dos substancias (“A” y “B”), cada una en varias dosis (la primera “0” es un control). Para cada dosis se muestrea una cantidad de células, y mediante un análisis microscópico se determina la cantidad de células con aberraciones.  Se desea determinar si hay diferencias en los efectos de las dos substancias; y en caso afirmativo, describirlas. Los datos son: sustancia, dosis (en mg./ml.), cantidad total de células muestreadas, y cantidad de células aberrantes. Tener en cuenta que “Dosis 0 de A” es lo mismo que “Dosis 0 de B”.

```{r}
# Ejercicio 3
tipo_cols <- cols(
  sustancia = col_factor(),
  dosis = col_double(),
  muestreadas = col_integer(),
  aberrantes = col_integer()
)
df3 <- read_csv("../data/3-3.csv", col_types = tipo_cols)

df3 <- df3 %>% 
  mutate(prop = aberrantes/muestreadas) %>%
  rowid_to_column()

knitr::kable(df3, col.names = c("Obs.", "Sustancia", "Dosis", "Muestreadas", "Aberrantes", "Prop."))
```

Inmediatamente observamos que la cantidad de células muestreadas no es la misma en todas las repeticiones. Para hacer una comparacón más justa, no intentaremos inferir directamente la cantidad de células aberrantes en cada muestra, sino la _proporción_ de ellas. A continuación, realizamos un primer gráfico de esta proporción en funcion de la dosis de cada sustancia:

```{r}
df3 %>%
  ggplot(aes(dosis, prop, color = sustancia)) +
  geom_line(linetype = "dashed") +
  geom_point() +
  labs(title = "Proporción de células aberrantes en función de la dosis")
```

La dosis de la substancia B parece afectar la proporción de células aberrantes de manera aproximadamente lineal, pero el comportamiento para la sustancia A es realmente misterioso. Uno podría suponer que la observación #3 es un _outlier_ y considerar eliminarla, pero contando con sólo tres observaciones con dosis positivas de la sustancia A, descartar una equivale a descartar un tercio de los datos disponibles.

A continuacón, hemos de elegir un modelo a ajustar. Una primera condición necesaria, será que estime idénticamente la proporción de células aberrantes cuando la dosis de la sustancia aplicada es nula. En segundo lugar, ya que no contamos con observaciones con dosis positivas de ambas sustancias, no tenemos otra opción más que considerar efectos aditivos, aunque químicamente resulte ingenuo tal planteo. Por último, considerando el gráfico anterior, plantearemos una relación dosis-respuesta cuadrática en la sustancia A. En un principio, tal idea puede resultar un mero artilugio matemático para "ajustar mejor", pero una somera búsqueda por la internet indica que existe tal cosa como una relación [dosis-respuesta cuadrática](https://www.rerf.or.jp/en/glossary/linquadra-en/). En [este](https://www.ncbi.nlm.nih.gov/pubmed/9566812) trabajo por ejemplo, los investigadores encuentran que un modelo cuadrático en la dosis de cafeína estima mucho mejor que otro lineal la actividad cerebral registrada en un electroencefalograma (EEG). Sean, para cada observación, $p, d_A, d_B, n$ la proporción de células aberrantes, la dosis de las sustancias A y B, y en número de células muestreadas, respectivamente. Además, llamemos $\pi$ a la proporción de células aberrantes "basal", en ausencia de sustancia alguna. Nuestro modelo será:

$$
p_i = \pi + \beta_1 \: d_{A,i} + \beta_2 \:(d_{A,i})^2 + \beta_3 \:d_{B,i} + \beta_4 \: n_i +\epsilon_i \quad \text{con } \epsilon_i \sim N(0, \sigma^2)
$$

```{r}
df3long <- df3 %>%
  spread(sustancia, dosis, fill = 0, sep = "")
```


```{r, eval = FALSE}
formulas <- list(
  prop ~ poly(sustanciaA, 2) + poly(sustanciaB, 1) + muestreadas,
  prop ~ poly(sustanciaA, 2) + poly(sustanciaB, 1) + muestreadas + 0,
  prop ~ poly(sustanciaA, 3) + poly(sustanciaB, 1) + muestreadas,
  prop ~ poly(sustanciaA, 2) + poly(sustanciaB, 2) + muestreadas,
  prop ~ poly(sustanciaA, 3) + poly(sustanciaB, 2) + muestreadas,
  prop ~ poly(sustanciaA, 3) + poly(sustanciaB, 2) + muestreadas + 0,
  prop ~ poly(sustanciaA, 2) + poly(sustanciaB, 2) + muestreadas + 0,
  prop ~ poly(sustanciaA, 2) + poly(sustanciaB, 2),
  prop ~ poly(sustanciaA, 2) + poly(sustanciaB, 1),
  prop ~ poly(sustanciaA, 2) + poly(sustanciaB, 1) + 0
)

modelos <- tibble(
  formula = formulas,
  modelo = as.character(formula),
  lm_call = map(formula, lm, data = df3long),
  resumen = map(lm_call, glance)) %>%
  unnest(resumen)
```

El ajuste es _sorprendentemente_ bueno, para lo descorazonadores que resultaban los datos originalmente. A continuación presentamos un resumen de los estadísticos principales, incluido el R^2 ajustado, el p-valor del test F de significatividad global, y los coeficientes estimados:

```{r}
lm3 <- lm(prop ~ poly(sustanciaA, 2) + poly(sustanciaB, 1) + muestreadas, df3long)

glance(lm3) %>%
  transmute(
    "R^2 aj." = as.character(signif(adj.r.squared, 3)),
    "F obs." = as.character(signif(statistic, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()

tidy(lm3) %>%
  transmute(
    "Coef." = term,
    "Estimado" = as.character(signif(estimate, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()
```

Tenemos muy pocos puntos como para observar tendencias en los residuos estudentizados en función de las proporciones predichas, pero lo que sí vemos, es que son todos realmente pequeños.
```{r}
augment(lm3, data = df3long) %>%
  ggplot(aes(.fitted, .std.resid)) +
  geom_point() +
  labs(title = "Residuos estudentizados en función de la proporción predicha",
       x = expression(hat(p)[i]), y = "Res. est.")

augment(lm3, data = df3long) %>%
  ggplot(aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "QQ-plot de los residuos de predicción",
     x = "Cuantil Teórico", y = "Residuo")

shapiro3 <- augment(lm3, data = df3long) %>%
  pull(".resid") %>%
  shapiro.test()
```

Por su parte, el QQ-plot no es muy satisfactorio, pero al mismo tiempo, con tan pocos datos, realmente no podíamos esperar nada mucho mejor. De hecho, para un $n$ tan pequeño, la mera elección de la secuencia de cuantiles de la distribución normal a comparar se vuelve determinante, y no hay test "numérico" que nos permita rechazar la normalidad (en este caso, por ejemplo, el test de Shapiro-Wilks univariado da un p-valor de `r signif(shapiro3$p.value, 3)`) .
 
Los coeficientes de $\pi$ (`(Intercept)`) y $n_i$ (`muestreadas`) son significativos a nivel $\approx 0.05$, mientras que los de $d_A, d_B$ son significativos a nivel $<0.001$. Como la regresión fue hecha sobre covariables generadas usando la función `poly` que computa polinomios _ortogonales_ para las dosis de sustancia, ninguno de los coeficientes se presta a una interpretación directa, ni siquiera la ordenada $\pi$. Lo que sí podemos hacer con las herramientas disponibles, es elegir una grilla de valores de $n, d_A, d_B$, realizar predicciones con el modelo ajustado y graficarlas. Así, se observa la principal limitación del enfoque elegido: para dosis por encima de 200 mg/ml (por fuera del soporte de los datos), el efecto de la sustancia A da predicciones _negativas_ para la proporción de células aberrantes:

```{r}
grilla <- crossing(
  muestreadas = c(200, 400),
  dosis = seq(0, 500, 5),
  sustancia = c("A", "B")
) %>%
  rowid_to_column() %>%
  spread(sustancia, dosis, fill = 0, sep = "")

augment(lm3, newdata = grilla) %>%
  transmute(
    muestreadas, sustanciaA, sustanciaB,
    prop = .fitted) %>%
  gather("sustancia", "dosis", -prop, -muestreadas) %>%
  filter(dosis != 0) %>%
  mutate(sustancia = str_sub(sustancia, -1, -1)) %>%
  ggplot(aes(dosis, prop, color = sustancia, linetype = factor(muestreadas))) +
  geom_line() +
  geom_point(data = df3) +
  scale_linetype_manual(values = c("dotted", "dashed")) + 
  coord_cartesian(ylim = c(0, 0.081)) +
  labs(title = "Proporción de células aberrantes predicha para valores seleccionados",
       linetype = "n")
```