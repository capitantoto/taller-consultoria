---
title: "Taller de Consultoria - TP3"
author: "Gonzalo Barrera Borla"
date: "23/09/2019"
output:
  pdf_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(tinytex.verbose = TRUE)
```

# Setup
```{r}
library(tidyverse) # manipulación de datos en general, graficos
library(broom) # limpieza y estructuracion de resultados de regresiones
library(GGally) # gráficos de perfiles, entre otros
```

# Ejercicio 1

```{r}
tipo_cols <- cols(
  maceta = col_integer(),
  cruz = col_double(),
  auto = col_double()
)
df1 <- read_csv("../data/3-1.csv", col_types = tipo_cols)
```

>  Los datos siguientes corresponden a un experimento realizado por Charles Darwin en 1876. En cada maceta se plantan dos brotes de maíz, uno producido por fertilización cruzada, y el otro por auto-fertilización. El objetivo era mostrar las ventajas de la fertilización  cruzada. Los datos son las altura finales de las plantas después de un período de tiempo. ¿Alguno de los dos tipos de maíz es demostrablemente mejor?. Si es así, ¿cómo se puede describir la diferencia?. 

Sea $\Omega_0$ la familia de distribuciones tal que

$$
\Omega_0 = \{F:F \text{ es absolutamente continua con única mediana en }0\}
$$
Sea $Y_i$ la altura del brote de maíz producido por fertilización cruzada de la  maceta $i\in\{1,\dots,n\}, n=15$, y $X_i$ la altura del producido por auto-fertilización. Supondremos además, razonablemente, que  $Y_i \stackrel{iid}{\sim} F_Y(t)=F(t-\theta_Y), \: F \in \Omega_0$ (es decir que $F_Y$ es absolutamente continua con única mediana en $\theta_Y$). Análogamente, $X_i \stackrel{iid}{\sim} F_X(t)=F(t-\theta_X)$. Como _"el objetivo era mostrar las ventajas de la fertilización  cruzada"_, una forma razonable de plantear este test será:

$$
H_0 := \theta_Y = \theta_X \quad \text{vs.} \quad H_1:= \theta_Y > \theta_X
$$
Como los brotes están naturalmente apareados en sus respectivas macetas, es razonable realizar un test de muestras apareadas. Para determinar qué clase de test realizar, nos resta contestar: ¿Es normal la distribución de las alturas de ambos tipos de brotes? Si la respuesta es "sí", podemos usar un "test t", mientras que si no será conveniente recurrir a alguna  alternativa no paramétrica, como el test de Wilcoxon de rangos signados, que sólo requiere que la distribución bajo la hipótesis nula sea simétrica.

```{r}
pv_norm_dif <- shapiro.test(df1$cruz - df1$auto)$p.value
pv_norm_auto <- shapiro.test(df1$auto)$p.value
pv_norm_cruz <- shapiro.test(df1$cruz)$p.value
```

Para testear la normalidad de los datos, utilizamos el test de Shapiro univariado. Para la diferencia $D_i=Y_i - X_i$, el p-valor es de `r signif(pv_norm_dif, 2)`, que dependiendo del nivel de significaión utilizado puede alcanzar o no para rechazar la normalidad. Si realizamos dos tests por separado, para la muestra $(X_1,\dots,X_n)$ de brotes autofertilizados obtenemos un p-valor `r signif(pv_norm_auto, 2)` con lo cual es razonable asumir su normalidad, pero al aplicar el test a la muestra de fertilización cruzada, obtenemos un p-valor de `r signif(pv_norm_cruz, 2)` que nos lleva a rechazar su normalidad. Resulta difícil suponer que por casualidad las diferencias de altura resulten normales si cada muestra no tiene una distribución normal subyacente, así que por seguridad convendrá recurrir a un test no paramétrico.

Nótese que bajo $H_0 := \theta_Y = \theta_X \Rightarrow \: F_X=F_Y$, de manera que la distribución de $Y_i - X_i$ será simétrica, y podemos utilizar un test de Wilcoxon para datos apareados con confianza.


```{r}
alfa <- 0.05
wcx_apar <- wilcox.test(df1$cruz, df1$auto, paired = T, alternative = "g",
                        conf.int = T, conf.level =1-alfa)
wcx_2samp <- wilcox.test(df1$cruz, df1$auto, paired = F, alternative = "g",
                        conf.int = T, conf.level = 1-alfa)
t_apar <- t.test(df1$cruz, df1$auto, paired = T, alternative = "g",
                        conf.int = T, conf.level = 1-alfa)
t_2samp <- t.test(df1$cruz, df1$auto, paired = F, alternative = "g",
                        conf.int = T, conf.level = 1-alfa)
```
Este test arroja un p-valor de `r signif(wcx_apar$p.value, 2)`, de manera que con el tradicional criterio de significación $\alpha = `r alfa`$, podemos rechazar la hipótesis nula y concluir que la diferencia entre las medianas de los brotes de fertilización cruzada y los autofertilizados es positiva. Aprovechando el hecho de que el estadístico $T^+$ es un estimador de Hodges-Lehmann, podemos encontrar también el intervalo de confianza de nivel `r 100*(1-alfa)`% correspondiente al test, que resulta ser $[`r wcx_apar$conf.int`)$.

Por último, y a modo ilustrativo, incluimos en la siguiente tabla los p-valores e intervalos de confianza de nivel `r 100*(1-alfa)`% correspondientes a cuatro alternativas de test razonables en este problema: 

```{r}
tribble(
  ~Muestras, ~Test, ~llamada,
  "apareadas", "Wilcoxon", wcx_apar,
  "2 muestras", "Wilcoxon", wcx_2samp,
  "apareadas", "T de Student", t_apar,
  "2 muestras", "T de Student", t_2samp) %>%
  mutate(
    "p-valor" = map_dbl(llamada, "p.value"),
    "Lím. inf. IC" = map(llamada, "conf.int") %>% map_dbl(1)
  ) %>%
  select(-llamada) %>%
  knitr::kable(digits = 4)
```

Es decir, que en todos los casos hubiésemos rechazado la hipótesis nula, pero la estimación de la diferencia en las medianas/medias hubiese sido bastante distinta.

# Ejercicio 2

> Se dan a continuación los tiempos de sobrevida (en unidades de 10 horas) de animales, sometidos a 3 tipos de veneno, y 4 tratamientos antitóxicos. Cada combinación veneno-tratamiento se prueba con 4 animales.  Describir la influencia de ambos factores en la sobrevida.  ¿Hay algún tratamiento demostrablemente mejor?

Para hacer más intuitiva la información, cambiamos las unidades de `sobrevida` de modo que esté en horas. Sea  $y_{ijk}$ la sobrevida del $k$-ésimo animal, sometida al tratamiento $j$ para el veneno $i$, en general planteamos $y_{ijk} = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon_{ijk}$, donde $i \in \{I, II, II\}, \: j \in \{A, B, C, D\}, \: k \in \{1, 2, 3, 4\}$ y $\epsilon_{ijk} \sim N(0, \sigma^2)$.

Para darnos una idea de la relación entre venenos y tratamientos, comenzamos graficando los perfiles:

```{r}
tipo_cols <- cols()
raw2 <- read_csv("../data/3-2.csv", col_types = tipo_cols)
df2 <- raw2 %>%
  gather("trt", "sobrevida", -veneno) %>%
  mutate(
    trt = as_factor(trt),
    sobrevida = sobrevida * 10)

df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(mean)%>%
  spread(veneno, sobrevida) %>%
  ggparcoord(2:4, "trt") +
  labs(title = "Sobrevida promedio por tratamiento",
       x = "Veneno", y = "Sobrevida (hs)", color = "Trat.")

df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(mean)%>%
  spread(trt, sobrevida) %>%
  ggparcoord(2:5, "veneno") +
  labs(title = "Sobrevida promedio por veneno",
       x = "Tratamiento", y = "Sobrevida (hs)", color = "Veneno")
```

A primera vista, no se observa paralelismo en ninguno de los dos gráficos Sin embargo, salvo un ligero entrecruzamiento en los perfiles de los venenos II y III para los tratamientos C y D, los perfiles no se cruzan en ningún otro punto, por lo que tal vez sea razonable ignorar las interacciones y considerar un modelo de efectos únicamente aditivos.

Por otra parte, debemos corroborar el fortísimo supuesto de _homocedasticidad_ de los $\epsilon_{ijk}$ que hicimos inicialmente. Seber [1977, p. 195] siguiendo a Scheffé menciona que cuando se cuenta con un diseño balanceado como aquí, la desigualdad en las varianzas para cada combinación de bloque y tratamiento no hace demasiado "daño", siempre y cuando la razón entre el mayor y el menor desvío estándar es menor a 2. Lamentablemente, nuestros datos son "bochornosos" en tal sentido:

```{r}
df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(lst(mean, sd)) %>%
  arrange(desc(sd)) %>%
  knitr::kable(
    digits = 3,
    caption = "La tasa entre los desvios de II:B y III:C es mayor a 26")
```

Antes de proseguir, nos convendrá entonces considerar una transformación [estabilizadora de la varianza](https://en.wikipedia.org/wiki/Variance-stabilizing_transformation) que al menos morigere esta situación. 

Si graficamos el desvío en función de la media de cada grupo, observamos una estructura razonablemente lineal en la media:

```{r}
df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(lst(mean, sd)) %>%
  ggplot(aes(mean, sd, color = trt, shape = veneno)) +
  geom_point() +
  labs(x = "Media", y = "Desvío", shape = "Veneno", color = "Trat.")
```

En este caso, donde $\sigma \approx k \times \mu$, la transformación sugerida es el logaritmo. Esto es razonable, ya que al hablar por ejemplo del logaritmo base 2 de la _sobrevida_, un tratamiento que duplica la supervivencia, aumentará $\log_2(y)$ en una unidad. Aplicando esta transformación, el la razón entre el máximo y mínimo desvíos anteriormente mencionada mejora bastante, pero sigue estando por encima de 7, muy lejos del corte de 2 que propone Seber.

Haremos un intento más, y en lugar de considerar la transformación logarítmica, buscaremos la transformación "óptima" según este criterio de optimalidad, de entre la familia de transformaciones [Box-Cox](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation) de un parámetro, que incluye el logaritmo natural como un caso especial cuando $\lambda=0$:

$$
y_i^{(\lambda)} =
\begin{cases}
 \dfrac{y_i^\lambda - 1}{\lambda} & \text{if } \lambda \neq 0, \\
 \ln y_i & \text{if } \lambda = 0,
\end{cases}
$$

Si graficamos la relación entre el mayor y menor desvío estándar por bloque y tratamiento para distintos $\lambda$, observamos que el mínimo se encuentra alrededor de $\lambda=-0.87$, que lleva la tasa de desvíos a $\approx 3.6$:

```{r}
boxcox <- function(y, lambda) {
  ifelse(lambda == 0, log(y), (y^lambda - 1)/lambda)
}
mejor_lambda <- function(lambdas) {
  tasas <- vector("numeric", length(lambdas))
  for (i in seq_along(lambdas)) {
    l <- lambdas[i]
    desvios <- df2 %>%
      mutate(y = map_dbl(sobrevida, boxcox, lambda = l)) %>%
      group_by(veneno, trt) %>%
      summarise(desvio = sd(y)) %>%
      pull("desvio")
    tasas[i] <- max(desvios)/min(desvios)
  }
  return(tibble(l = lambdas,t = tasas))
}

lambdas <- mejor_lambda(seq(-1.5, 0, 0.01))
lambdas %>%
  ggplot(aes(l, t)) +
  geom_line() +
  labs(x = expression(lambda), y=expression(paste("max ", sigma, " / min ", sigma)))
```

Reducir la tasa de desvíos a 3.6 sigue sin ser suficiente para el criterio originalmente autoimpuesto, pero tampoco está demasiado lejos, y es una enorme mejoría respecto a la tasa original de más de 26, así que aplicaremos la transformación de Box-Cox y calificaremos momentáneamente de "tolerable" la heterocedasticidad restante. Lo que sí, para ayudar a la comprensión, en lugar de tomar el óptimo $\lambda^{\star}=-0.87$, tomaremos el mucho más interpretable $\lambda=-1$, que consigue una tasa de desvíos similar (4.12), pero provee una transformación más clara: $g(y) = 1 - \tfrac{1}{y}$, que cuando $y \in (1, + \infty) \Rightarrow g(y) \in (0, 1)$.

Aplicamos la transformación, y volvemos a graficar los perfiles.

```{r}
lambdas %>%
  filter(l == 1 | l == 0 | (-0.9 < l & l < -0.8) | l == -1)
```

Como la variable respuesta $y$ indica la _sobrevida_ de los animales, un procedimiento razonable sería transformarla por el logaritmo natural, de manera que 

Usando el comando `anova` sobre la salida de `lm`, obtenemos fácilmente una tabla con los datos necesarios para testear esta hipótesis. Por un lado, los coeficientes significativos al 5% del modelo multiplicativo ajustado son

```{r}
mult <- lm(sobrevida ~ veneno * trt, df2)
tidy(mult) %>%
  dplyr::select(term, estimate, p.value) %>%
  filter(p.value <= 0.1) %>%
  arrange(p.value) %>%
  knitr::kable(digits = 4)
```

# No hay entrecruzamientos escandalosos, pareciera que B>D>C>A y I>II>III
# con un pequenio cruce entre I:D y II:D





```{r}
# venenoIII:trtB es la unica interaccion significativa, pero
tidy(anova(mult))
# las interacciones en conjunto no son significativas
# calcular Mint/Mtrat, esta cerca de 0.1, no sign.

# Paso al modelo aditivo
adit <- lm(sobrevida ~ veneno + trt, df2)
tidy(adit) %>%
  arrange(p.value)

# Analizo las varianzas por blq/trt
df2var <- df2 %>%
  group_by(veneno, trt) %>%
  summarise_all(lst(mean, sd))

grouped_df2 <- group_by(df2, veneno, trt)




df2 <- df2 %>%
  mutate(y = map_dbl(sobrevida, boxcox, -1))

lm2 <- lm(y ~ veneno + trt, df2)
summary(lm2)
anova(lm2)

df2 %>%
  ggplot(aes(veneno, y, color = trt)) +
  geom_boxplot()

TukeyHSD(aov(sobrevida ~ veneno + trt, df2))
```

```{r}

# Ejercicio 3
tipo_cols <- cols(
  substancia = col_factor(),
  dosis = col_double(),
  muestreadas = col_integer(),
  aberrantes = col_integer()
)
df3 <- read_csv("../data/3-3.csv", col_types = tipo_cols)

df3 <- df3 %>%
  mutate(
    prop = aberrantes/muestreadas,
    substancia0 = ifelse(dosis==0, "O", levels(substancia)))

lm3a <- lm(prop ~ dosis * substancia, df3)
summary(lm3a)
lm3b <- lm(prop ~ dosis * substancia0, df3)
summary(lm3b)
lm3c <- glm(prop ~ substancia*dosis, df3, weights = muestreadas,
            family=binomial)
summary(lm3c)

#lm3d <- glm(aberrantes ~ muestreadas + dosis*substancia, df3, family=binomial)
```