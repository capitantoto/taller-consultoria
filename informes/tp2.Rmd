---
title: "Taller de Consultoria - TP2 - Selección de Modelos"
author: "Gonzalo Barrera Borla"
date: "11/10/2019"
output:
  pdf_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(tinytex.verbose = TRUE)
library(tidyverse)
library(broom)
```

## Introducción

En los tres ejercicios de esta práctica se busca

- (a) elegir un modelo para predecir la variable $y$ a partir de una muestra aleatoria $X$ de un conjunto de covariables $x_1, x_2, \dots, x_n$, y
- (b) dar una medida del error de predicción asociado al modelo.

A diferencia del TP1, los tres problemas que ahora nos competen ilustran situaciones tan específicas que comprender la relación entre las covariables sin la ayuda de un técnico en el campo es una tarea vana. La _opacidad_ del conjunto de covariables (que no es una caja negra, pero tampoco es transparente) nos obliga a intentar ajustar varios modelos en cada situación, y elegir el "mejor" entre ellos, según algún criterio de bondad a definir. Luego, en cada ejercicio intentaremos encontrar el "mejor modelo lineal", siguiendo el mismo procedimiento:

1. **Selección de Modelos**: Compararemos varios modelos posibles entre sí, utilizando como criterio de bondad el ECM de predicción por "validación cruzada deje-uno-fuera" (LOOCV, por sus siglas en inglés). Para evitar el sobreajuste a los datos, utilizaremos la empíricamente eficiente "Regla de 1 Desvío Estándar"[1]. Cconsideraremos que el "mejor modelo" no es el que tenga el menor ECM, sino aquél de menor complejidad (_id est_, con menor cantidad de regresores) con un ECM no más de 1DE por encima del mínimo ECM en términos absolutos.

2. **Análisis de residuos**: Elegido el mejor modelo según la R1DE, revisaremos los residuos de predicción para comprobar que (a) no posean ninguna estructura obvia y (b) sean aproximadamente normales. De violarse severamente alguno de estos supuestos, descartaremos la observación elegida y volveremos al paso 1. De no observar mayores irregularidades, confirmaremos la elección de modelo.

Armados de un criterio sólido de selección de modelos, a continuación hacemos sólo una breve sinopsis de los resultados obtenidos aplicando el mismo criterio a cada problema sin detenernos demasiado en ninguno. El lector avieso notará que los conjuntos de modelos sobre los cuales elegiremos "el mejor" o "el más parsimonioso" distan de ser exhaustivos. Esto es adrede, ya que cualquier enumeración completa de los modelos es una quimera, y estamos realizando este ejercicio casi a modo ilustrativo. En la vida real, sería irresponsable ofrecer un modelo así elegido, sin entender a fondo las covariables involucradas.

Vale la pena recordar que cuando reportemos p-valores y distintos estadísticos de calidad de ajuste para cada modelo, los valores no se pueden tomar literalmente, ya que su interpretación natural ha quedado invalidada por el proceso de selección de modelos y eliminación de observaciones atípicas. A lo sumo, constituyen una medida informal de la bondad del ajuste propuesto, para los datos observados, e la misma manera, el ECM (o si se prefiere, su raíz) provee una medida informal de la precisión del modelo.


```{r metodos}
loocv <- function(formula, data) {
  n <- nrow(data)
  preds <- vector("double", n)
  for (i in seq.int(n)) {
    lm_fit <- lm(formula, data[-i,])
    preds[i] <- predict(lm_fit, newdata = data[i,])
  }
  return(preds)
}

sqdif <- function(x, y) { (x-y)^2 }
resumir <- function(data, ycol, modelos) {
  y <- data[[ycol]]
  enframe(modelos, name = "nombre", value = "formula") %>%
  mutate(
    loocv_preds = map(formula, loocv, data),
    sqerrs = map(loocv_preds, sqdif, y),
    msehat = map_dbl(sqerrs, mean),
    msehatvar = map_dbl(sqerrs, var))
}

imprimir_resumen <- function(res, n = nrow(res)) {
  res %>%
  transmute(
    modelo = map_chr(formula, deparse),
    ec = signif(msehat, 4),
    desvio = signif(sqrt(msehatvar), 4))%>%
  arrange(ec) %>%
  head(n) %>%
  knitr::kable(
    col.names = c("Modelo", "ECM", "Desvío")
  )
}
```

## Ejercicio 1

La definición de las covariables en el ejercicio tiene algunas particularidades.  Por un lado, la "gravedad API" [2] es una escala de densidad específica, propuesta por el American Petroleum Institute. Según las clasificaciones tradicionales, todos los tipos de petróleo evaluados tienen una gravedad mayor a 31.1° (i.e., menor a 870 kg/m3) y por ende son "crudos ligeros". Las otras dos variables con curiosa escala, A y V, están expresadas en "punto ASTM". La "Sociedad Americana para Pruebas y Materiales", o ASTM por sus siglas en inglés, tiene publicados más de 12.000 (!) estándares a la fecha, así que saber a cuál hace referencia la descripción es como buscar una aguja en un pajar. Si fuésemos hombres de apuestas, seguramente nos jugaríamos por el [3] _ASTM D1837-17: Standard Test Method for Volatility of Liquefied Petroleum (LP) Gases_. Lamentablemente, el estándar fue retirado de circulación en 2017 al haber sido supeditado por métodos más directos y eficientes como la cromatografía de gases.

Como el enunciado pide predecir R en función de G, P, A y V, ignoraremos las variables "tipo" y "corrida", que entendemos son desconocidas al momento de predecir.

### Selección de Modelo

A continuación, presentamos en forma de tabla el ECM de LOOCV (y su desvio) para los mejores de entre una selección arbitratria de modelos posibles, que incluye todos los modelos aditivos y multiplicativos de 1 a 4 covariables:

```{r ej1}
tipo_cols <-  cols(
  tipo = col_factor(),
  corrida = col_integer(),
  G = col_double(),
  P = col_double(),
  A = col_double(),
  V = col_integer(),
  R = col_double()
)

df1 <- read_csv("../data/2-1.csv", col_types = tipo_cols) %>%
  rowid_to_column("id")

modelos1 <- list(
  APGV = R ~ A + P + G + V,
  mAPGV = R ~ A * P * G * V,
  A = R ~ A,
  P = R ~ P,
  G = R ~ G,
  V = R ~ V,
  AP = R ~ A + P,
  AG = R ~ A + G,
  AV = R ~ A + V,
  PG = R ~ P + G,
  PV = R ~ P + V,
  GV = R ~ G + V,
  mAP = R ~ A * P,
  mAG = R ~ A * G,
  mAV = R ~ A * V,
  mPG = R ~ P * G,
  mPV = R ~ P * V,
  mGV = R ~ G * V,
  APG = R ~ A + P + G,
  APV = R ~ A + P + V,
  AGV = R ~ A + G + V,
  PGV = R ~ P + G + V,
  mAPG = R ~ A * P * G,
  mAPV = R ~ A * P * V,
  mAGV = R ~ A * G * V,
  mPGV = R ~ P * G * V,
  cuadratico_completo = R ~ (A + P + G + V)^2
)

res1 <- resumir(df1, "R", modelos1)
imprimir_resumen(res1, 12)
```

Llamemos $\omega_{abs}$ y $\omega_{1sd}$ a los modelos con menor ECM en términos absolutos, y al mejor modelo según la R1DE, respectivamente. Resulta entonce que $\omega_{abs}:= R \sim A + P + G + V$, con 5 regresores (incluyendo a la ordenada), y dentro de un desvío estándar de su ECM encontramos $\omega_{1sd} := R \sim A + V$, con un ECM un 19% mayor, pero sólo 3 regresores.

### Análisis de Residuos

Para asegurarnos de que el modelo no sólo ajuste bien sino que además esté libre de sesgos sistemáticos, ajustamos $\omega_{1sd}$ sobre todos los datos y realizamos

- un _scatterplot_ de los residuos estandarizados contra los valores predichos y
- un QQ-plot de los residuos absolutos.

```{r }
lm1 <- lm(R ~ A + V, df1)
df1 <- augment(lm1, df1)
df1 %>%
  ggplot(aes(.fitted, .std.resid)) +
  geom_point() +
  labs(title = "Residuos estandarizados en función del valor predicho",
       x = "Rendimiento Predicho", y = "Residuo")
```

No se observa estructura evidente ni valores extremos de los residuos estandarizados al graficarlos contra predichos. Tampoco hay grandes alejamientos de la normalidad en el QQ-plot, así que confirmamos la selección previa. 

```{r }
plot(lm1, which = 2, id.n = 5)
```

Finalmente, reportamos los principales estadísticos del modelo $R \sim A + V$ ajustado _con todas las observaciones_ junto con los valores de sus coeficientes:

```{r}
glance(lm1) %>%
  transmute(
    "R^2 aj." = as.character(signif(adj.r.squared, 3)),
    "F obs." = as.character(signif(statistic, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()

tidy(lm1) %>%
  transmute(
    "Coef." = term,
    "Estimado" = as.character(signif(estimate, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()
```

## Ejercicio 2

Si las variables del ejercicio 1 estaban curiosamente definidas, éstas dan aún más lugar para la imaginación: un "flujo de aire" $X_1$ en unidades desconocidas, una concentración de ácido $X_3$ en porcentaje (¿de qué? ¿de los reactivos totales? ¿por qué no se usará el pH?), y una pérdida también en unidades desconocidas. Como especifica el ejercicio, excluimos la variable $dia$ de todos los modelos a comparar.


```{r}
tipo_cols <- cols(
  dia = col_integer(),
  X1 = col_integer(),
  X2 = col_integer(),
  X3 = col_double(),
  Y = col_double()
)
df2 <- read_csv("../data/2-2.csv", col_types = tipo_cols) %>%
  rowid_to_column("id")
```



### Selección de Modelo

Consideramos los modelos aditivos y multiplicativos para 2 y 3 variables, además de todos los modelos de 1 sola covariable basados en (a) una potencia entera ($\leq 3$) de una variable original o (b) la interacción de algunas de ellas. Los ECM estimados por LOOCV para los 10 mejores modelos resultan ser:

```{r }
modelos2 <- list(
  cte = Y ~ 1,
  X1X2 = Y ~ X1 + X2,
  X1X3 = Y ~ X1 + X3,
  X2X3 = Y ~ X2 + X3,
  mX1X2 = Y ~ X1 * X2,
  mX1X3 = Y ~ X1 * X3,
  mX2X3 = Y ~ X2 * X3,
  X1yX2 = Y ~ X1:X2,
  X1yX3 = Y ~ X1:X3,
  X2yX3 = Y ~ X2:X3,
  X1yX2yX3 = Y ~ X1:X2:X3,
  X1 = Y ~ X1,
  X2 = Y ~ X2,
  X3 = Y ~ X3,
  X1e2 = Y ~ I(X1^2),
  X2e2 = Y ~ I(X2^2),
  X3e2 = Y ~ I(X3^2),
  X1e3 = Y ~ I(X1^3),
  X2e3 = Y ~ I(X2^3),
  X3e3 = Y ~ I(X3^3),
  Y ~ X1 + X2 + X3,
  Y ~ X1 * X2 * X3,
  cuadratico = Y ~ (X1 + X2 + X3)^2,
  cubico = Y ~ (X1 + X2 + X3)^3
)

res2 <- resumir(df2, "Y", modelos2)
imprimir_resumen(res2, 10)
```

Casualmente, el modelo de menor ECM es también uno de mínima complejidad, con sólo 2 regresores (el modelo de sólo ordenada es el de peor ECM entre los evaluados), así que en principio, $\omega_{abs} \equiv \omega_{1sd} := Y \sim X_1\times X_2$.

### Análisis de residuos

```{r}
lm2 <- lm(Y ~ X1:X2, df2)
augment(lm2, df2) %>%
  ggplot(aes(.fitted, .std.resid)) +
  geom_point() +
  labs(title = "Residuos estandarizados en función del valor predicho",
       x = "Pérdida Predicha", y = "Residuo est.")
```

Esta vez, sí observamos cierta estructura en los residuos, pero ninguna tendencia obvia. Si realizamos el mismo gráfico para otros modelos al azar, se nota esta misma seudo-agrupación, así que por el momento no hacemos nada más.

```{r}
plot(lm2, which = 2, id.n = 5, labels.id = df2$"id")
```

Aquí, observamos cierto alejamiento de la normalidad para los residuos de predicción en algunas observaciones. Para asegurarnos de no haber sesgado la elección de modelo por estos valores extremos, removemos la observación más alejada de la recta cuantil-cuantil (#21) y rankeamos todos los modelos nuevamente por LOOCV. 
 Esto hace que el modelo con el menor ECM absoluto pase a ser $Y \sim X_1 + X_2$, pero $Y \sim X_1\times X_2$ sigue siendo el mejor modelo según la R1DE. Cuando volvemos a graficar los residuos del modelo ajustado sin la observación 21, vemos que la observación #9 sigue estando bastante alejada de la recta cuantil-cuantil, así que también la descartamos. Repetimos este proceso iterativamente, eliminando primero la observación #9, y luego la #7. En cada caso, $\omega_{abs} :=Y \sim X_1 + X_2$, y $\omega_{1sd} :=Y \sim X_1\times X_2$ sigue siendo el mejor modelo según la R1DE. Sin las observaciones $(21, 9, 7)$, el scatterplot de residuos y la recta cuantil-cuantil no muestran mayores irregularidades:

```{r}
outs <- c(21, 9, 7)
lm2.2 <- lm(Y ~ X1:X2, df2[-outs,])

augment(lm2.2, df2[-outs,]) %>%
  ggplot(aes(.fitted, .std.resid)) +
  geom_point() +
  labs(title = "Residuos estandarizados en función del valor predicho",
       x = "Pérdida Predicha", y = "Residuo est.")

plot(lm2.2, which = 2, id.n = 5, labels.id = df2[-outs,]$id)
```

Cuando comparamos tanto los estadísticos globales como los coeficientes particulares del modelo ajustado con y sin las observaciones $(21, 9, 7)$, observamos una sutil mejora en el $R^2_{aj}$, pero coeficientes iguales hasta el cuarto decimal en ambos casos. Haciendo la misma salvedad de siempre sobre la interpretabilidad de los p-valores, a continuación reportamos los resultados del modelo ajustado _con todas las observaciones_ para el modelo elegido, $Y \sim X_1 \times X_2$:

```{r}
glance(lm2) %>%
  transmute(
    "R^2 aj." = as.character(signif(adj.r.squared, 3)),
    "F obs." = as.character(signif(statistic, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()

tidy(lm2) %>%
  transmute(
    "Coef." = term,
    "Estimado" = as.character(signif(estimate, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()
```


## Ejercicio 3

Investigando en la Internet, descubrimos que efectivamente, la espectroscopía del espectro infrarrojo cercano (NIR, por sus siglas en inglés) se utiliza en agricultura [4] para medir la calidad de distintos cultivos y suelos, ya que es un método no-invasivo y relativamente barato. El "estándar dorado", sin embargo, para medir el contenido de nitrógeno en sustancias orgánicas, e indirectamente el contenido proteico de las mismas, es el método de Kjeldahl [5]. Vale aclarar que ambos métodos son formas indirectas de medir la cantidad de proteína en una muestra, y por lo tanto son susceptibles a manipulaciones. En un incidente particularmente cruento [6], en 2008 más de 54,000 bebés fueron hospitalizados y al menos 12 murieron por cálculos renales o insuficiencia proteica cuando varias marcas de leche en polvo adulteraron sus productos con melamina, un químico compuesto en 67% m/m por nitrógeno, más conocido como la materia prima para los revestimientos de fórmica. Esta anécdota ilustra que hacer inferencia sobre cierto soporte de los datos (muestras de calibración) y luego aplicar los resultados obtenidos a muestras por fuera de ese dominio (leche adulterada), no garantiza resultados válidos. 

Siendo ésta data de _calibración_ de un instrumento, asumimos que las muestras de trigo no están adulteradas, pero tampoco tenemos mucha información sobre la cual trabajar, ya que ni siquiera conocemos las longitudes de onda medidas, como para poder estimar un perfil de absorción de radiación. Así las cosas, con 6 covariables disponibles, sólo los posibles modelos lineales en ellas ascienden a $2^6=64$, de modo que _tras bambalinas_ primero recurrimos al método `GGally::ggpairs` para graficar los "scatterplots" y calcular la correlación entre cada par de variables disponibles, pero no obtuvimos demasiada información: las seis variables $L_i$ están tan correlacionadas que todos los scatterplots se ven iguales: una línea recta con pendiente positiva.
A continuación, sacamos la artillería pesada, y usamos el método `olsrr::ols_all_subset` para ajustar todos los modelos lineales posibles, elegir un subconjunto de los más prometedores, y calcular el ECM según LOOCV como hasta ahora. 

```{r ej3}
tipo_cols <- cols(
  muestra = col_integer(),
  Y = col_double(),
  L1 = col_integer(),
  L2 = col_integer(),
  L3 = col_integer(),
  L4 = col_integer(),
  L5 = col_integer(),
  L6 = col_integer()
)
df3 <- read_csv("../data/2-3.csv", col_types = tipo_cols) %>%
  rowid_to_column("id")

modelos3 <- list(
  sinmuestra = Y ~ L1 + L2 + L3 + L4 + L5 + L6,
  cuadrado = Y ~ (L1 + L2 + L3 + L4 + L5 + L6)^2,
  L3456 = Y ~ L3 + L4 + L5 + L6,
  L345 = Y ~ L3 + L4 + L5,
  L34 = Y ~  L3 + L4,
  mL345 = Y ~ L3 * L4 * L5,
  mL34 = Y ~  L3 * L4,
  Y ~ L3:L4,
  Y ~ L3:L5,
  Y ~ L4:L5,
  Y ~ L3:L4:L5,
  L34_cuadrado = Y ~ (L3 + L4)^2,
  L3 = Y ~ L3,
  L4 = Y ~ L4
)

res3 <- resumir(df3, "Y", modelos3)
imprimir_resumen(res3)
```

En principio, el mejor modelo "absoluto" es $\omega_{abs} := Y \sim L_3 + L_4 + L_5$, y dentro de 1 ddesvío estándar encontramos $\omega_{1sd} := Y \sim L_3 + L_4$, con 3 regresores. Considerando que el rango de de Y es [`r signif(range(df3$Y, 3))`], un ECM de 0.066 (RMSE $\approx 0.25$) es realmente bueno.

### Análisis de Residuos

Como siempre, graficamos los residuos para estudiar cualquier estructura remanente.

```{r}
lm3 <- lm(Y ~ L3 + L4, df3)
augment(lm3, df3) %>%
  ggplot(aes(.fitted, .std.resid, label = id)) +
  geom_point() +
  geom_label(data = ~filter(., abs(.std.resid) > 2)) +
  labs(title = "Residuos estandarizados en función del valor predicho",
       x = "Pérdida Predicha", y = "Residuo est.")
```

Esta vez, sí observamos un potencial candidato a outlier en la obs. #18, pero ninguna tendencia obvia.

```{r}
plot(lm3, which = 2, id.n = 5)
```

En el QQ-plot de los residuos, resulta evidente que algunas observaciones se alejan considerablemente de los cuantiles esperados. Seguimos el mismo procedimiento de antes de ir eliminando observaciones y recompuntado el ECM para encontrar el mejor modelo según la R1DE, que resulta en la siguiente secuencia de eliminación de observaciones: $(18, 19, 8, 7, 9)$. En cada caso, $Y \sim L_3 + L_4$ resulta ser el mejor modelo tanto en ECM absoluto como según la R1DE siguió siendo $Y \sim L_3 + L_4$, y al eliminarlas tanto los residuos contra predichos como el QQ-plot resultan muy razonables.
```{r}
outs <- c(18, 19, 8, 7, 9)
lm3.2 <- lm(Y ~ L3 + L4, df3[-outs,])

augment(lm3.2, df3[-outs,]) %>%
  ggplot(aes(.fitted, .std.resid, label = id)) +
  geom_point() +
  geom_label(data = ~filter(., abs(.std.resid) > 2)) +
  labs(title = "Residuos estandarizados en función del valor predicho",
       x = "Pérdida Predicha", y = "Residuo est.")

plot(lm3.2, which = 2, id.n = 3, labels.id = df3[-outs,]$id)
```

Los coeficientes finales no variaron demasiado entre el ajuste con todas las observaciones y sin las "alejadas de la normalidad", con lo cual preferimos conservarlas y reportar estadísticos sobre el modelo ajustado con todas las observaciones:

$$
\begin{split}
\text{Sin } (18, 19, 8, 7, 9)&: \hat{Y} = 30.13 + 0.23 L_3 - 0.21 L_4 \\
\text{Con todas}&: \hat{Y} = 31.17 + 0.24 L_3 - 0.22 L_4
\end{split}
$$

Al igual que antes, concluimos con los estadísticos principales y coeficientes para el modelo elegido, $Y \sim L_3 + L_4$

```{r}
glance(lm3) %>%
  transmute(
    "R^2 aj." = as.character(signif(adj.r.squared, 3)),
    "F obs." = as.character(signif(statistic, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()

tidy(lm3) %>%
  transmute(
    "Coef." = term,
    "Estimado" = as.character(signif(estimate, 3)),
    "P-valor" = as.character(signif(p.value, 3))
  ) %>%
  knitr::kable()
```

## Referencias

- [1] Justificacion empírica de la "regla de un desvío estándar" - [enlace](https://stats.stackexchange.com/questions/80268/empirical-justification-for-the-one-standard-error-rule-when-using-cross-validat)
- [2] Gravedad API - [enlace](https://en.wikipedia.org/wiki/API_gravity)
- [3] ASTM D1837-17: Standard Test Method for Volatility of Liquefied Petroleum (LP) Gases (Withdrawn 2017) - [enlace](https://www.astm.org/Standards/D1837.htm)
- [4] Espectroscopía infrarroja cercana (NIR) en agricultura - [enlace](https://en.wikipedia.org/wiki/Near-infrared_spectroscopy#Agriculture)
- [5] Método Kjeldahl - [enlace](https://en.wikipedia.org/wiki/Kjeldahl_method)
- [6] Adulteración de leche para bebés en 2008 - [enlace](https://en.wikipedia.org/wiki/2008_Chinese_milk_scandal)
- [7] "The Road Not Taken", de Robert Forst - [enlace](https://www.poetryfoundation.org/poems/44272/the-road-not-taken)